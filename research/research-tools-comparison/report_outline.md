# 系统性调研工具对比研究 - 报告大纲

## 报告规格（最终版）

- **受众**：技术人员、研究者、知识工作者
- **目的**：评估和选择适合不同研究场景的系统性调研工具/方法
- **范围**：适用于技术调研、课题研究、学科探索的工具和方法论
- **研究对象类型**：
  * 技术栈调研（框架选型、语言特性）
  * 学术课题（文献综述、理论探索）
  * 行业/市场研究
  * 跨学科知识整合
- **时间范围**：2024-2026年可用工具
- **地域**：全球工具，优先中英文支持
- **输出格式**：Markdown
- **引用风格**：脚注 + 文末参考文献
- **长度目标**：10000-15000字
- **语气**：专业、客观、实操导向

## 章节结构

### 1. 执行摘要 (500字)
**必需元素：**
- 研究背景：系统性调研的重要性和挑战
- 核心发现：3-5个关键结论
  * Claude Code skills 提供端到端自动化调研工作流
  * AI 原生工具在不同环节各有优势（发现、分析、可视化）
  * 传统方法论仍是质量控制的金标准
  * 工具组合策略优于单一工具
  * 学习成本与自动化程度呈反比关系
- 目标读者价值：如何根据场景选择合适工具

**引用要求：** 每个结论至少1个来源支持

---

### 2. 研究问题与范围 (300字)
**必需元素：**
- 核心研究问题
  * 有哪些工具和方法可以系统性调研技术/课题/学科？
  * 它们在不同场景下的表现如何？
  * 如何选择和组合这些工具？
- 范围界定
  * **包含**：AI工具、传统方法论、文献管理工具、MCP服务器、Claude Code skills
  * **排除**：纯理论方法论（无可操作工具）、已停止维护的工具、仅限特定学科的工具
- 时间和地理范围
  * 2024-2026年可用工具
  * 全球可访问，优先中英文支持

---

### 3. 研究方法论 (400字)
**必需元素：**
- 数据来源
  * 官方文档（Claude Code skills, PRISMA, 工具官网）
  * 学术文献（arXiv, PMC）
  * 专业评测（大学图书馆指南、技术博客）
  * 用户反馈（实际使用案例）
- 搜索策略
  * 多源搜索：WebSearch, Exa, open-websearch
  * 中英文关键词：AI research tools, systematic review, 系统性调研, 文献综述
  * 工具发现：MCP服务器目录、GitHub、产品评测网站
- 质量评估标准
  * A级：官方文档、标准指南、同行评审论文
  * B级：专业评测、学术机构推荐
  * C级：博客、用户分享（交叉验证后使用）
- 已知局限
  * 部分新兴工具缺乏长期使用数据
  * 成本信息可能随时变化（已标注时间）
  * 未涵盖所有小众工具

**引用要求：** 引用证据收集文件中的源列表

---

### 4. 工具分类框架 (800字)
**必需元素：**
- **按自动化程度分类**（4个层级）
  1. 全自动化（Claude Code skills）
  2. AI 辅助（NotebookLM, Elicit, Consensus）
  3. 半自动化（ResearchRabbit, Litmaps）
  4. 手动+辅助（Zotero, PRISMA）

- **按研究类型分类**（5个类型）
  1. 技术调研
  2. 学术综述
  3. 文献映射
  4. 多文档问答
  5. 引用管理

- **按证据质量控制分类**（4个等级）
  1. 严格控制
  2. 中度控制
  3. 基础控制
  4. 用户主导

**可视化要求：** 包含分类维度表格

**引用要求：** 每个分类说明都引用具体工具案例

---

### 5. Claude Code Skills 深度对比 (1500字)
**必需元素：**

#### 5.1 deep-research skill
- **核心能力**
  * 9步严格工作流：格式契约 → 证据收集 → 并行起草 → UNION合并
  * 多轮完整起草（避免单次起草偏差）
  * 严格引用验证和证据表
- **适用场景**
  * 正式研究报告（需要固定格式）
  * 文献综述、市场分析、政策简报
  * 需要多源证据整合和溯源
- **工作流程示例**
  * [引用 S1 详细说明9步流程]
- **优势**
  * 端到端自动化
  * 格式合规性强
  * 证据可追溯
- **限制**
  * 需要明确的格式要求
  * 学习曲线较陡
  * 适合结构化调研，不适合探索式研究

#### 5.2 tech-research skill
- **核心能力**
  * 多源搜索工具矩阵（WebSearch, Exa, Context7, deepwiki等）
  * GitHub 活跃度筛选机制（排除僵尸项目）
  * 双文档输出：概览报告 + 上手指南
  * 默认中文输出，代码/术语保留英文
- **适用场景**
  * 技术选型和框架对比
  * 开源项目调研
  * 技术趋势分析
- **工作流程示例**
  * [引用 S2 详细说明活跃度筛选和多源搜索策略]
- **优势**
  * 针对技术调研优化
  * 自动过滤低质量项目
  * 支持中英文双语环境
- **限制**
  * 主要针对技术主题
  * 依赖多个 MCP 服务器
  * 不适合纯学术理论研究

#### 5.3 对比总结表
| 维度 | deep-research | tech-research |
|------|--------------|---------------|
| 目标场景 | 通用研究报告 | 技术调研 |
| 自动化程度 | 极高 | 极高 |
| 格式控制 | 严格 | 灵活 |
| 证据质量控制 | 严格（证据表+引用验证） | 中度（活跃度筛选） |
| 多语言支持 | 通用 | 中文优先 |
| 学习曲线 | 陡峭 | 中等 |
| 输出形式 | 单一报告 | 双文档（概览+指南） |
| 推荐用户 | 需要正式报告的研究者 | 技术选型决策者 |

**引用要求：** S1, S2 作为主要来源

---

### 6. AI 原生调研工具对比 (2500字)
**必需元素：**

#### 6.1 文献发现与问答类
**NotebookLM** [S6, S14, S15]
- 功能：文档摘要、交互式问答、笔记生成
- 数据来源：用户上传文档
- 成本：免费（Google）
- 优势：最受研究者欢迎，多文档合成能力强
- 限制：无主动搜索，依赖用户提供文档
- 适用场景：已有文献集合的深度分析

**Elicit** [S4, S6, S7]
- 功能：AI 科学研究助手，文献搜索和答案生成
- 数据来源：学术数据库
- 用户规模：500万+研究者
- 成本：免费层 + 付费订阅
- 优势：专注学术研究，答案带引用
- 限制：主要针对科学/医学领域
- 适用场景：学术文献综述

**Consensus** [S6, S7]
- 功能：文献搜索、答案验证、相关研究推荐
- 数据来源：学术数据库
- 优势：答案验证功能，避免AI幻觉
- 适用场景：需要多源验证的研究问题

**Perplexity** [S12]
- 功能：带引用的答案搜索，深度研究模式
- 数据来源：全网搜索
- 优势：RAG架构，实时信息
- 限制：学术深度不如专用工具
- 适用场景：跨领域快速调研

#### 6.2 文献可视化与映射类
**ResearchRabbit** [S13, S16, S17, S19]
- 功能：文献映射、引用网络可视化、相关论文推荐
- 数据来源：Semantic Scholar
- 成本：免费
- 优势：免费、易用、可视化出色
- 限制：依赖单一数据源
- 适用场景：文献综述初期，快速建立知识图谱

**Litmaps** [S13, S17, S18]
- 功能：动态交互式文献地图、监控新论文
- 数据来源：多个学术数据库
- 成本：免费层 + 付费订阅
- 优势：可视化最强，支持协作
- 限制：免费版功能受限
- 适用场景：长期跟踪研究领域

**Connected Papers** [S13, S17, S19]
- 功能：引用关系图谱、相似论文发现
- 数据来源：Semantic Scholar
- 成本：免费层 + 付费订阅
- 优势：简单直观，快速上手
- 限制：单次只能围绕1篇种子论文
- 适用场景：基于已知论文扩展阅读

**Inciteful** [S17, S19]
- 功能：高级引用关系可视化、文献集合分析
- 数据来源：学术数据库
- 成本：免费
- 优势：支持多篇种子论文
- 适用场景：基于文献集合的关系分析

#### 6.3 引用分析与可信度评估类
**Scite** [S16, S17, S18, S19]
- 功能：引用上下文分析、支持/反对引用区分、可信度评估
- 数据来源：学术数据库
- 成本：免费层 + 机构订阅
- 优势：独特的引用分类（支持/反对/提及）
- 适用场景：评估研究可信度、发现争议

#### 6.4 综合对比表
| 工具 | 类型 | 数据源 | 成本 | 核心优势 | 主要限制 | 推荐场景 |
|------|------|--------|------|----------|----------|----------|
| NotebookLM | 问答 | 用户上传 | 免费 | 多文档合成 | 无主动搜索 | 深度分析已有文献 |
| Elicit | 搜索+问答 | 学术库 | Freemium | 500万用户，学术专注 | 领域限制 | 学术综述 |
| Consensus | 搜索+验证 | 学术库 | Freemium | 答案验证 | - | 多源验证需求 |
| Perplexity | 搜索+问答 | 全网 | Freemium | 实时信息 | 学术深度不足 | 跨领域快速调研 |
| ResearchRabbit | 可视化 | Semantic Scholar | 免费 | 完全免费 | 单一数据源 | 文献综述初期 |
| Litmaps | 可视化 | 多数据库 | Freemium | 可视化最强 | 免费版受限 | 长期跟踪领域 |
| Connected Papers | 可视化 | Semantic Scholar | Freemium | 简单直观 | 单篇种子限制 | 扩展阅读 |
| Inciteful | 可视化 | 学术库 | 免费 | 多篇种子 | - | 文献集合分析 |
| Scite | 引用分析 | 学术库 | Freemium | 引用分类 | - | 可信度评估 |

**引用要求：** 每个工具的描述都引用至少1个来源

---

### 7. 传统研究方法论和工具 (1500字)
**必需元素：**

#### 7.1 系统性综述方法论
**PRISMA (2020)** [S3, S9]
- 定义：系统性综述和元分析的报告标准
- 核心组件
  * 27项清单
  * 流程图（原始综述和更新综述）
  * 摘要清单
- 2024更新状态
  * PRISMA for NMA (网络元分析)
  * PRISMA-P 2025 (协议更新)
  * PRISMA-ScR (范围综述更新)
  * PRISMA-EE (健康经济评估，2026发布)
- 适用场景：医学、社会科学系统性综述
- 优势：国际公认标准，严格质量控制
- 限制：流程复杂，耗时长

**系统文献综述 (SLR)** [S22, S23]
- 定义：全面、客观收集和评估特定主题所有相关研究
- 核心步骤
  1. 明确研究问题
  2. 制定检索策略
  3. 文献筛选
  4. 质量评估
  5. 数据提取
  6. 综合分析
  7. 报告撰写
- 适用领域：医疗保健、环境科学、计算机科学
- 工具支持：Covidence, DistillerSR, EPPI-Reviewer

#### 7.2 质性研究方法
**扎根理论 (Grounded Theory)** [S25, S26, S27]
- 提出者：Glaser & Strauss (1967)
- 核心理念："从下往上"建构理论，基于原始数据归纳
- 核心流程
  1. 产生研究问题
  2. 数据收集（访谈、观察）
  3. 开放编码
  4. 主轴编码
  5. 选择性编码
  6. 理论饱和
- 适用场景：探索性研究、理论构建
- 限制：高度依赖研究者判断，难以复现

**内容分析法** [S27]
- 定义：系统化分析文本内容，识别模式和主题
- 类型：定量内容分析、定性内容分析
- 与扎根理论区别：预设分析框架 vs 归纳生成理论
- 适用场景：媒体研究、政策分析

**方法对比表** [S27]
| 方法 | 理论预设 | 编码方式 | 目标 | 适用场景 |
|------|----------|----------|------|----------|
| 扎根理论 | 无 | 开放编码 | 建构理论 | 探索性研究 |
| 内容分析 | 有框架 | 结构化编码 | 验证假设 | 描述性研究 |
| 话语分析 | 有理论背景 | 语境编码 | 揭示权力关系 | 社会语言学 |
| 主题分析 | 灵活 | 主题编码 | 识别模式 | 通用质性研究 |

#### 7.3 文献管理工具
**Zotero** [S28, S29]
- 类型：开源免费
- 核心功能：文献收集、组织、引用生成
- 优势：完全免费，插件丰富，社区活跃
- 限制：界面不如商业工具精美
- 协作：支持群组，无人数限制（但同步空间有限）
- 推荐用户：预算受限的个人和小团队

**Mendeley** [S28, S29]
- 类型：商业工具（Elsevier）
- 核心功能：文献管理 + PDF 标注 + 协作
- 2024重大变化：取消扩展机构许可，大团队需付费
- 优势：协作笔记出色，PDF 管理强大
- 限制：无全文搜索，免费私有群组限25人
- 推荐用户：重视协作笔记的研究团队

**EndNote** [S28, S29]
- 类型：商业工具（Clarivate）
- 核心功能：企业级文献管理，高度定制
- 优势：最多1000人协作，高级搜索，三向同步
- 限制：成本高，学习曲线陡
- 推荐用户：大型机构、企业研究部门

**对比总结**
| 工具 | 成本 | 协作上限 | 全文搜索 | 定制性 | 推荐场景 |
|------|------|----------|----------|--------|----------|
| Zotero | 免费 | 无限（同步空间有限） | 是 | 高（插件） | 个人和小团队 |
| Mendeley | Freemium | 25人（免费） | 否 | 中 | 协作团队 |
| EndNote | 付费 | 1000人 | 是 | 极高 | 企业/机构 |

**引用要求：** S3, S9, S22, S23, S25-S29

---

### 8. MCP 服务器调研能力 (800字)
**必需元素：**

#### 8.1 MCP 生态概述 [S5, S20, S21]
- Model Context Protocol (MCP)：AI-工具集成的开源标准
- Claude Code 作为 MCP 客户端，可连接数百个外部工具
- 2026年重大特性：MCP Tool Search（动态工具发现，减少85%上下文开销）

#### 8.2 调研相关 MCP 服务器
**Context7** [S5, S20]
- 功能：实时查询库和框架的最新文档
- 使用方式：在提示词中添加 "use context7"
- 适用场景：技术调研中需要最新 API 文档
- 案例：`创建 React Server Component，使用 Next.js 14 最新模式 - use context7`

**Perplexity AI MCP** [S5, S20]
- 功能："研究助手"式交互，外包网络搜索并返回带来源的摘要
- 适用场景：快速获取特定问题的多源答案

**deepwiki MCP** [S5, S20]
- 功能：获取 GitHub 项目的深度文档
- 数据来源：deepwiki.com 仓库
- 适用场景：开源项目技术调研

**Sequential Thinking MCP** [S5]
- 功能：结构化问题解决，反思式思维过程
- 适用场景：复杂问题的系统性分析
- 优势：保持跨推理链的上下文

**exa MCP** [web_search_exa, get_code_context_exa]
- 功能：高质量网络搜索 + 代码上下文获取
- 适用场景：技术文档搜索、代码示例查找

**open-websearch MCP** [search, fetchGithubReadme, fetchCsdnArticle等]
- 功能：多引擎网络搜索（DuckDuckGo, Bing, Brave）
- 适用场景：中英文内容搜索

#### 8.3 MCP 在调研工作流中的角色
- **证据收集阶段**：Context7, exa, open-websearch 提供多源信息
- **技术验证阶段**：deepwiki 提供项目文档，exa 提供代码示例
- **问题解决阶段**：Sequential Thinking 提供结构化思维
- **与 skills 的协同**：tech-research skill 默认使用多个 MCP 服务器

**引用要求：** S5, S20, S21

---

### 9. 综合对比矩阵 (1500字)
**必需元素：**

#### 9.1 多维度评分表
维度说明：
- 自动化程度：1（完全手动）- 5（全自动）
- 证据质量控制：1（用户主导）- 5（严格验证）
- 学习曲线：1（极易上手）- 5（专业级）
- 成本：1（完全免费）- 5（高成本）
- 中文支持：1（无）- 5（原生支持）
- 协作能力：1（单人）- 5（大规模团队）

| 工具/方法 | 类型 | 自动化 | 质量控制 | 学习曲线 | 成本 | 中文支持 | 协作 | 适用场景 |
|-----------|------|--------|----------|----------|------|----------|------|----------|
| **Claude Code Skills** |
| deep-research | AI工作流 | 5 | 5 | 4 | 1* | 5 | 3 | 正式报告、文献综述 |
| tech-research | AI工作流 | 5 | 4 | 3 | 1* | 5 | 3 | 技术选型、开源调研 |
| **AI 原生工具** |
| NotebookLM | 问答 | 4 | 3 | 1 | 1 | 4 | 2 | 已有文献深度分析 |
| Elicit | 搜索+问答 | 4 | 4 | 2 | 2 | 3 | 2 | 学术综述 |
| Consensus | 搜索+验证 | 4 | 4 | 2 | 2 | 3 | 2 | 多源验证 |
| Perplexity | 搜索+问答 | 4 | 3 | 1 | 2 | 4 | 1 | 跨领域快速调研 |
| ResearchRabbit | 可视化 | 3 | 2 | 2 | 1 | 3 | 3 | 文献映射 |
| Litmaps | 可视化 | 3 | 2 | 2 | 2 | 3 | 4 | 长期领域跟踪 |
| Connected Papers | 可视化 | 3 | 2 | 1 | 2 | 3 | 2 | 扩展阅读 |
| Scite | 引用分析 | 3 | 4 | 2 | 3 | 3 | 2 | 可信度评估 |
| **传统工具** |
| PRISMA | 方法论 | 1 | 5 | 5 | 1 | 4 | 4 | 系统性综述 |
| 扎根理论 | 方法论 | 1 | 4 | 5 | 1 | 5 | 2 | 理论构建 |
| Zotero | 文献管理 | 2 | 2 | 2 | 1 | 4 | 3 | 文献组织 |
| Mendeley | 文献管理 | 2 | 2 | 2 | 2 | 4 | 3 | 协作笔记 |
| EndNote | 文献管理 | 2 | 2 | 3 | 5 | 4 | 5 | 企业级管理 |

*注：Claude Code skills 需要 Claude Code 订阅，但 skills 本身免费

#### 9.2 场景适配矩阵
| 研究场景 | 推荐工具组合 | 理由 |
|----------|-------------|------|
| **技术选型调研** | tech-research + Context7 MCP + deepwiki MCP | 自动化技术调研，最新文档，项目活跃度筛选 |
| **学术文献综述** | deep-research + Elicit + Scite + Zotero | 严格格式控制，学术搜索，引用验证，文献管理 |
| **快速主题探索** | NotebookLM + ResearchRabbit + Perplexity | 低学习成本，可视化关系，跨领域搜索 |
| **系统性综述（医学）** | PRISMA + Covidence + Zotero + Scite | 金标准流程，专业筛选工具，引用可信度 |
| **开源项目评估** | tech-research + deepwiki MCP + GitHub | 活跃度筛选，深度文档，代码分析 |
| **跨学科知识整合** | deep-research + Litmaps + Consensus | 多源整合，可视化跨领域连接，验证一致性 |
| **理论构建（质性）** | 扎根理论 + NVivo + Mendeley | 归纳理论，编码工具，协作笔记 |

#### 9.3 成本-收益分析
**免费工具组合（适合个人研究者）**
- 核心：Zotero + ResearchRabbit + NotebookLM
- MCP服务器：Context7 + open-websearch
- 能力：文献管理 + 可视化 + 问答分析
- 成本：$0/月
- 限制：无高级AI功能，协作受限

**标准组合（适合小团队）**
- 核心：Claude Code (deep-research/tech-research) + Elicit基础版 + Mendeley
- 能力：自动化调研 + 学术搜索 + 协作管理
- 成本：约 $30-50/月
- 优势：显著提升效率，保持专业质量

**专业组合（适合机构）**
- 核心：Claude Code + Elicit机构版 + Scite机构版 + EndNote
- 能力：全流程自动化 + 深度分析 + 大规模协作
- 成本：约 $200-500/月
- 优势：最高效率，最严格质量控制

**引用要求：** 综合所有已收集的来源

---

### 10. 场景化推荐决策树 (1000字)
**必需元素：**

#### 10.1 决策流程图（文本版）
```
[开始] 您的调研目标是什么？
├─ [技术/工具选型]
│  ├─ 需要正式报告？
│  │  ├─ 是 → tech-research skill + 格式化模板
│  │  └─ 否 → Context7 MCP + deepwiki MCP + 手动整理
│  └─ 项目已确定，只需深入了解？
│     └─ deepwiki MCP + NotebookLM（上传README和文档）
│
├─ [学术研究/文献综述]
│  ├─ 需要发表级别系统性综述？
│  │  └─ PRISMA + Covidence + Zotero + Scite
│  ├─ 课程作业或一般综述？
│  │  └─ deep-research skill + Elicit + Zotero
│  └─ 快速了解领域现状？
│     └─ ResearchRabbit + Consensus + NotebookLM
│
├─ [市场/行业分析]
│  ├─ 需要正式报告（给领导/客户）？
│  │  └─ deep-research skill + Perplexity + Exa MCP
│  └─ 内部决策参考？
│     └─ Perplexity + NotebookLM + 手动整理
│
└─ [理论构建/探索性研究]
   ├─ 质性研究？
   │  └─ 扎根理论 + NVivo + Mendeley
   └─ 跨学科整合？
      └─ deep-research skill + Litmaps + Semantic Scholar
```

#### 10.2 关键决策因素
**因素1：正式程度**
- 需要正式报告 → Claude Code skills（格式控制强）
- 内部参考 → AI工具组合（灵活度高）
- 探索性 → 可视化工具（启发性强）

**因素2：时间预算**
- < 1天 → NotebookLM + Perplexity（最快）
- 1-3天 → tech-research skill（自动化）
- 1-2周 → deep-research skill + 人工验证（高质量）
- > 1月 → PRISMA + 专业工具（系统性综述）

**因素3：团队规模**
- 个人 → Zotero + 免费AI工具
- 2-5人 → Mendeley + Claude Code
- 5-25人 → Mendeley机构版 + Litmaps
- > 25人 → EndNote + Elicit机构版

**因素4：预算**
- $0 → Zotero + ResearchRabbit + NotebookLM
- < $50/月 → Claude Code + Elicit基础版
- < $200/月 → 上述 + Scite + Mendeley
- > $200/月 → 全套专业工具 + 机构订阅

#### 10.3 常见错误与避坑指南
**错误1：单一工具依赖**
- 症状：只用ChatGPT或只用传统方法
- 后果：效率低或质量差
- 解决：工具组合，AI自动化+人工验证

**错误2：忽略证据溯源**
- 症状：直接使用AI生成内容，不验证来源
- 后果：学术不端或决策失误
- 解决：使用 deep-research skill 或 Scite 进行引用验证

**错误3：过度追求自动化**
- 症状：完全依赖AI，不进行批判性思考
- 后果：遗漏重要洞察，盲目接受错误结论
- 解决：AI辅助+人工判断，特别是在理论构建阶段

**错误4：工具学习成本过高**
- 症状：选择PRISMA但团队无经验
- 后果：项目停滞，学习曲线陡峭
- 解决：从简单工具开始（NotebookLM），逐步进阶

**引用要求：** 基于证据综合推断

---

### 11. 局限性与未来趋势 (600字)
**必需元素：**

#### 11.1 研究局限性
- **数据时效性**：部分工具更新快，本报告数据截至2026年2月
- **成本变动**：定价策略可能调整（如Mendeley 2024取消机构许可）
- **工具覆盖**：未涵盖所有小众工具（如领域特定工具）
- **主观性**：工具评分包含研究者主观判断
- **缺乏长期数据**：部分新工具（如AiReview）缺乏长期使用反馈

#### 11.2 未来趋势预测
**趋势1：AI深度研究成为主流** [S12]
- RAG（检索增强生成）模式普及
- 从"搜索+阅读"到"问答+验证"
- 代表：Perplexity Deep Research, Claude deep-research

**趋势2：工具整合加速**
- MCP 生态扩展，更多工具互联
- Zotero + Obsidian + NotebookLM 类工作流流行 [S14]
- API互通，减少工具切换成本

**趋势3：质量控制自动化**
- AI自动执行PRISMA流程（如AiReview [S10]）
- 引用可信度自动评估（Scite模式扩展）
- 偏见检测和数据质量评分

**趋势4：个性化研究助手**
- 基于个人研究历史的定制推荐
- 自动跟踪领域进展（Litmaps监控功能）
- 多模态输入（语音、图像、视频文献）

**引用要求：** S10, S12, S14

---

### 12. 参考文献 (按来源编号)
**必需元素：**
- 完整的来源列表（S1-S29）
- 每个来源包含：标题、作者/机构、日期、URL
- 按质量等级分组（A/B/C）

**格式示例：**
```
## A 级来源（官方文档、权威指南）
[S1] Claude Code. "deep-research skill". 2024+. 本地文件: /Users/wmm/.claude/skills/deep-research/skill.md
[S2] Claude Code. "tech-research skill". 2024+. 本地文件: /Users/wmm/.claude/skills/tech-research/skill.md
...

## B 级来源（专业评测、学术文章）
[S6] Marco Huberts & Ayat Abourashed. "Best AI Research Tools for Scientists & Researchers 2025". Motif.bio. 2025-11. https://www.motif.bio/blog/ai-research-tools-researchers-2025
...

## C 级来源（博客、知识分享）
[S22] "系统性文献综述（SLR）：科学探索的'罗盘'". 知乎. 2024. https://zhuanlan.zhihu.com/p/1888995678593729368
...
```

---

## 格式要求总结

1. **标题层级**：严格使用 H1-H4，不跳级
2. **引用格式**：脚注 `[S1]` + 文末完整列表
3. **表格**：所有对比都使用Markdown表格
4. **代码块**：决策树用代码块包裹
5. **字数**：每章节不超过规定字数（±10%可接受）
6. **语言**：中文简体，技术术语保留英文
7. **证据要求**：每个关键论断都有引用

## 下一步：并行起草

根据此大纲，将使用 Task tool 生成 3 个并行版本的完整报告，然后 UNION 合并。
